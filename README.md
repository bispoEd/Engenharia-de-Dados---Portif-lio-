🧭 Estrutura por Nível
🔰 Nível Iniciante

    Projeto 01 – Coleta de dados com Python (API OpenWeather)
    Extração de dados em tempo real via API, tratamento simples e exportação para CSV.

    Projeto 02 – ETL com Pandas (dados de vendas)
    Pipeline de extração, limpeza e transformação de dados de vendas simulados.

    Projeto 03 – Dashboard com Streamlit
    Visualização interativa dos dados de vendas com gráficos e filtros.

🔁 Nível Intermediário

    Projeto 04 – ETL automatizado com Apache Airflow (local)
    Criação de DAGs para automatizar a rotina de processamento de dados com agendamento diário.

    Projeto 05 – Armazenamento em Banco de Dados (PostgreSQL)
    Inserção dos dados processados em uma tabela relacional utilizando SQLAlchemy.

    Projeto 06 – Integração com Data Warehouse (BigQuery)
    Upload dos dados para o Google BigQuery com autenticação via Service Account, prontos para análises em larga escala.

🚀 Principais Habilidades Demonstradas

    Coleta de dados via API e arquivos locais

    Processamento e transformação com Pandas

    Visualização com Streamlit + Altair

    Orquestração de tarefas com Apache Airflow

    Persistência com PostgreSQL

    Integração com Google BigQuery

    Organização modular e reutilizável de pipelines


📌 Próximos passos (nível avançado)

    Pipeline distribuído com Databricks + PySpark

    Monitoramento e data observability

    Qualidade de dados com ferramentas como Great Expectations

    Projeto Capstone completo de ponta a ponta com arquitetura em nuvem

Esse programa foi construído de forma didática e escalável, sendo ideal para comprovar minhas habilidades técnicas e evolução prática na área de Engenharia de Dados.
